{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "FER.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Xyj6jkPXEtY",
        "outputId": "df0f1342-bdcc-4f9b-f3e8-840c39f6dd81"
      },
      "source": [
        "!pip install kaggle"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kaggle in /usr/local/lib/python3.6/dist-packages (1.5.10)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.23.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from kaggle) (2020.12.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.41.1)\n",
            "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle) (4.0.1)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from kaggle) (2.8.1)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.24.3)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from kaggle) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->kaggle) (3.0.4)\n",
            "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle) (1.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "Gi0JOl1Xcjjf",
        "outputId": "bf2ba634-dc13-4246-836e-cd2fd8f5b70b"
      },
      "source": [
        "from google.colab import files\r\n",
        "files.upload()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-bd31ee61-1240-4edf-aa98-32d4e389d7ab\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-bd31ee61-1240-4edf-aa98-32d4e389d7ab\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"abdullahnasser\",\"key\":\"4fc39131739e56c8d0c792b31085a58b\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6Tns-Lucn1V"
      },
      "source": [
        "!mkdir -p ~/.kaggle\r\n",
        "!cp kaggle.json ~/.kaggle/\r\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5esVbXmcrEu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c465cb3-dcfe-49a2-8963-d1ceb805ff5a"
      },
      "source": [
        "!kaggle datasets download -d ashishpatel26/facial-expression-recognitionferchallenge"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading facial-expression-recognitionferchallenge.zip to /content\n",
            " 84% 81.0M/96.6M [00:01<00:00, 45.3MB/s]\n",
            "100% 96.6M/96.6M [00:01<00:00, 54.1MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N793lrqZctAO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08b0881f-7f1b-49de-e491-61acd52ec211"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "facial-expression-recognitionferchallenge.zip  kaggle.json  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ELe7AqU6csvg"
      },
      "source": [
        "import zipfile\r\n",
        "zip_ref = zipfile.ZipFile('facial-expression-recognitionferchallenge.zip', 'r')\r\n",
        "zip_ref.extractall('files')\r\n",
        "zip_ref.close()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "_stCxWlRXEtd",
        "outputId": "e14a9dfa-c002-4acd-889e-65ced00e26a6"
      },
      "source": [
        "import pandas as pd\r\n",
        "data = pd.read_csv(r'/content/files/fer2013/fer2013/fer2013.csv')\r\n",
        "data.head()"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emotion</th>\n",
              "      <th>pixels</th>\n",
              "      <th>Usage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   emotion                                             pixels     Usage\n",
              "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n",
              "1        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n",
              "2        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n",
              "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n",
              "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "2FK3oVJ2XEti",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "outputId": "115cec2e-da16-41d3-cb4d-323c5cb475e7"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "\n",
        "sns.countplot(data.emotion)"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f56497c0940>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEGCAYAAACUzrmNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAASBklEQVR4nO3de7BeVX3G8e8DEVG8AJJSTMAwFa14qWAGsThqpUW8AXVQcUQDpZP+gRRbWxXtSIsyo/V+qU4ZLgakAoM3tI6WAt4rmggVSaRm8EIyINHgfQSDv/7xrugREtZ78OzznpPz/cycOXuvffudTJLn7LXXu3aqCkmS7slOky5AkjT3GRaSpC7DQpLUZVhIkroMC0lS16JJFzCEvfbaq5YtWzbpMiRpXlmzZs0PqmrxtrbtkGGxbNkyVq9ePekyJGleSfLd7W2zG0qS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktS1Q36CW5ppn33KUyddwjY99XOfnXQJWiC8s5AkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpK5BwyLJ3yW5Psk3knwwya5J9k9ydZL1SS5Oskvb975tfX3bvmzKeU5r7TckecaQNUuS7m6wsEiyBPhbYHlVPQbYGTgOeBPw9qp6OHAbcFI75CTgttb+9rYfSQ5sxz0aOBJ4b5Kdh6pbknR3Q3dDLQLul2QRcH/gZuDpwKVt+yrgmLZ8dFunbT88SVr7RVV1e1V9G1gPHDJw3ZKkKQYLi6raCLwF+B6jkPgxsAb4UVVtabttAJa05SXATe3YLW3/h0xt38Yxv5FkZZLVSVZv2rRp5n8gSVrAhuyG2oPRXcH+wEOB3Rh1Iw2iqs6qquVVtXzx4sVDXUaSFqQhu6H+HPh2VW2qql8BHwYOA3Zv3VIAS4GNbXkjsC9A2/5g4IdT27dxjCRpFgwZFt8DDk1y//bs4XBgLXAVcGzbZwXwsbZ8WVunbb+yqqq1H9dGS+0PHAB8ZcC6JUl3sai/y71TVVcnuRT4GrAFuAY4C/hP4KIkb2ht57RDzgEuSLIe2MxoBBRVdX2SSxgFzRbg5Kq6c6i6JUl3N1hYAFTV6cDpd2m+kW2MZqqqXwLP3855zgTOnPECJUlj8RPckqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVLXokkXIEk7snVnXjnpErbpUa99+rT2H/TOIsnuSS5N8s0k65I8KcmeSS5P8q32fY+2b5K8K8n6JF9PcvCU86xo+38ryYoha5Yk3d3Q3VDvBD5VVX8M/AmwDng1cEVVHQBc0dYBngkc0L5WAu8DSLIncDrwROAQ4PStASNJmh2DdUMleTDwFOAEgKq6A7gjydHA09puq4DPAK8CjgbOr6oCvtzuSvZp+15eVZvbeS8HjgQ+OFTt0o7kPa/4+KRL2K6XvfW5ky5BYxryzmJ/YBNwXpJrkpydZDdg76q6ue1zC7B3W14C3DTl+A2tbXvtkqRZMmRYLAIOBt5XVQcBP+e3XU4AtLuImomLJVmZZHWS1Zs2bZqJU0qSmiHDYgOwoaqubuuXMgqP77fuJdr3W9v2jcC+U45f2tq21/47quqsqlpeVcsXL148oz+IJC10g4VFVd0C3JTkka3pcGAtcBmwdUTTCuBjbfky4KVtVNShwI9bd9WngSOS7NEebB/R2iRJs2Toz1mcAlyYZBfgRuBERgF1SZKTgO8CL2j7fhJ4FrAe+EXbl6ranOT1wFfbfmdsfdgtSZodg4ZFVV0LLN/GpsO3sW8BJ2/nPOcC585sdZKkcTndhySpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkrrGCoskV4zTJknaMd3jFOVJdgXuD+zVXjyUtulB+B5sSVoweu+z+Bvg5cBDgTX8Nix+ArxnwLq0gzns3YdNuoRt+uIpX5x0CdK8cI9hUVXvBN6Z5JSqevcs1SRJmmPGelNeVb07yZ8Cy6YeU1XnD1SXJGkOGSssklwA/BFwLXBnay7AsJCkBWDcd3AvBw5s78mel57wj3Mz19a8+aWTLkGSusb9nMU3gD8cshBJ0tw17p3FXsDaJF8Bbt/aWFVHDVKVJGlOGTcs/nnIIiRJc9u4o6E+O3QhkqS5a9zRUD9lNPoJYBfgPsDPq+pBQxUmSZo7xr2zeODW5SQBjgYOHaooSdLcMu1ZZ2vko8AzBqhHkjQHjdsN9bwpqzsx+tzFLwepSJI054w7Guq5U5a3AN9h1BUlSVoAxn1mceLQhUiS5q5xX360NMlHktzavj6UZOnQxUmS5oZxH3CfB1zG6L0WDwU+3tokSQvAuGGxuKrOq6ot7ev9wOIB65IkzSHjhsUPkxyfZOf2dTzwwyELkyTNHeOGxV8BLwBuAW4GjgVOGKgmSdIcM+7Q2TOAFVV1G0CSPYG3MAoRSdIObtw7i8dtDQqAqtoMHDRMSZKkuWbcsNgpyR5bV9qdxbif/t45yTVJPtHW909ydZL1SS5Osktrv29bX9+2L5tyjtNa+w1JnGZEkmbZuGHxVuB/krw+yeuBLwH/OuaxpwLrpqy/CXh7VT0cuA04qbWfBNzW2t/e9iPJgcBxwKOBI4H3Jtl5zGtLkmbAWGFRVecDzwO+376eV1UX9I5rH9x7NnB2Ww/wdODStssq4Ji2fHRbp20/fMoMtxdV1e1V9W1gPXDIOHVLkmbGuA+4qaq1wNppnv8dwCuBrVOcPwT4UVVtaesbgCVteQlwU7vWliQ/bvsvAb485ZxTj5EkzYKxw2K6kjwHuLWq1iR52lDXmXK9lcBKgP3222/oy0maJWcef+ykS9iu137g0v5OO4hpv89iGg4DjkryHeAiRt1P7wR2T7I1pJYCG9vyRmBfgLb9wYw++Peb9m0c8xtVdVZVLa+q5YsX++FySZpJg4VFVZ1WVUurahmjB9RXVtWLgasYfagPYAXwsbZ8WVunbb+yqqq1H9dGS+0PHAB8Zai6JUl3N1g31D14FXBRkjcA1wDntPZzgAuSrAc2MwoYqur6JJcwel6yBTi5qu6c/bIlaeGalbCoqs8An2nLN7KN0UxV9Uvg+ds5/kzgzOEqlCTdkyGfWUiSdhCGhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroGC4sk+ya5KsnaJNcnObW175nk8iTfat/3aO1J8q4k65N8PcnBU861ou3/rSQrhqpZkrRtQ95ZbAFeUVUHAocCJyc5EHg1cEVVHQBc0dYBngkc0L5WAu+DUbgApwNPBA4BTt8aMJKk2TFYWFTVzVX1tbb8U2AdsAQ4GljVdlsFHNOWjwbOr5EvA7sn2Qd4BnB5VW2uqtuAy4Ejh6pbknR3s/LMIsky4CDgamDvqrq5bboF2LstLwFumnLYhta2vfa7XmNlktVJVm/atGlG65ekhW7wsEjyAOBDwMur6idTt1VVATUT16mqs6pqeVUtX7x48UycUpLUDBoWSe7DKCgurKoPt+bvt+4l2vdbW/tGYN8phy9tbdtrlyTNkiFHQwU4B1hXVW+bsukyYOuIphXAx6a0v7SNijoU+HHrrvo0cESSPdqD7SNamyRpliwa8NyHAS8BrktybWt7DfBG4JIkJwHfBV7Qtn0SeBawHvgFcCJAVW1O8nrgq22/M6pq84B1S5LuYrCwqKovANnO5sO3sX8BJ2/nXOcC585cdZKk6fAT3JKkLsNCktRlWEiSugwLSVKXYSFJ6jIsJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK6DAtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktRlWEiSuhZNugCN53tnPHbSJWzTfq+7btIlSJoF3llIkroMC0lSl2EhSeoyLCRJXYaFJKnLsJAkdRkWkqQuw0KS1GVYSJK65k1YJDkyyQ1J1id59aTrkaSFZF6ERZKdgX8DngkcCLwoyYGTrUqSFo55ERbAIcD6qrqxqu4ALgKOnnBNkrRgpKomXUNXkmOBI6vqr9v6S4AnVtXLpuyzEljZVh8J3DBgSXsBPxjw/EOz/smy/smZz7XD8PU/rKoWb2vDDjPrbFWdBZw1G9dKsrqqls/GtYZg/ZNl/ZMzn2uHydY/X7qhNgL7Tllf2tokSbNgvoTFV4EDkuyfZBfgOOCyCdckSQvGvOiGqqotSV4GfBrYGTi3qq6fYEmz0t01IOufLOufnPlcO0yw/nnxgFuSNFnzpRtKkjRBhoUkqcuwmKb5PO1IknOT3JrkG5OuZbqS7JvkqiRrk1yf5NRJ1zQdSXZN8pUk/9vq/5dJ13RvJNk5yTVJPjHpWqYryXeSXJfk2iSrJ13PdCXZPcmlSb6ZZF2SJ83q9X1mMb427cj/AX8BbGA0SutFVbV2ooWNKclTgJ8B51fVYyZdz3Qk2QfYp6q+luSBwBrgmHn0Zx9gt6r6WZL7AF8ATq2qL0+4tGlJ8vfAcuBBVfWcSdczHUm+Ayyvqnn5obwkq4DPV9XZbVTo/avqR7N1fe8spmdeTztSVZ8DNk+6jnujqm6uqq+15Z8C64Alk61qfDXys7Z6n/Y1r35TS7IUeDZw9qRrWWiSPBh4CnAOQFXdMZtBAYbFdC0BbpqyvoF59B/WjiLJMuAg4OrJVjI9rQvnWuBW4PKqmlf1A+8AXgn8etKF3EsF/FeSNW16oPlkf2ATcF7rBjw7yW6zWYBhoXklyQOADwEvr6qfTLqe6aiqO6vq8YxmIDgkybzpCkzyHODWqloz6Vp+D0+uqoMZzV59cuuWnS8WAQcD76uqg4CfA7P6zNSwmB6nHZmg1tf/IeDCqvrwpOu5t1r3wVXAkZOuZRoOA45q/f4XAU9P8oHJljQ9VbWxfb8V+AijbuX5YgOwYcrd6KWMwmPWGBbT47QjE9IeEJ8DrKuqt026nulKsjjJ7m35fowGSXxzslWNr6pOq6qlVbWM0d/7K6vq+AmXNbYku7WBEbTumyOAeTMqsKpuAW5K8sjWdDgwq4M75sV0H3PFHJx2ZFqSfBB4GrBXkg3A6VV1zmSrGtthwEuA61q/P8BrquqTE6xpOvYBVrURdTsBl1TVvBt+Oo/tDXxk9DsHi4D/qKpPTbakaTsFuLD9onojcOJsXtyhs5KkLruhJEldhoUkqcuwkCR1GRaSpC7DQpLUZVhIE5Dk8UmeNWX9qPk2i7EWFofOShOQ5ARGM6C+bNK1SOPwzkIaQ5Lj2/sork3y721SwJ8leXN7P8V/JzkkyWeS3JjkqHbcrknOa+9RuCbJn7UPVZ0BvLCd74VJTkjynnbMsiRXJvl6kiuS7Nfa35/kXUm+1K5x7OT+RLTQGBZSR5JHAS8EDmsTAd4JvBjYjdG0F48Gfgq8gdE0Hn/JKAwATmY0Q/ljgRcBqxj9u3sdcHFVPb6qLr7LJd8NrKqqxwEXAu+asm0f4MnAc4A3zvTPKm2P031IfYcDTwC+2qaLuB+jacbvALZOGXEdcHtV/SrJdcCy1v5kRv/5U1XfTPJd4BGd6z0JeF5bvgD41ynbPlpVvwbWJtn79/mhpOkwLKS+MPpN/7TfaUz+oX770O/XwO0AVfXrJEP927r9LnVJs8JuKKnvCuDYJH8AkGTPJA8b89jPM+qyIskjgP2AGxh1Wz1wO8d8idHMrrRjP38v65ZmjGEhdbT3fP8To7esfR24nNGzg3G8F9ipdU1dDJxQVbczep/FgVsfcN/lmFOAE9u1XgKcOhM/h/T7cOisJKnLOwtJUpdhIUnqMiwkSV2GhSSpy7CQJHUZFpKkLsNCktT1/7fuu868bXgBAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGT6_uXKD4t3"
      },
      "source": [
        "It is evident that majority of the data is in classes {0, 2, 3, 4, 6}.\r\n",
        "So we will use those classes only"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARgAWHXUXEtj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "deede193-09f7-4c82-b5f3-96c34e3523b5"
      },
      "source": [
        "data['Usage'].unique()"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Training', 'PublicTest', 'PrivateTest'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whZjKgdWXEtk"
      },
      "source": [
        "data = data.query('emotion==0 or emotion==2 or emotion==3 or emotion==4 or emotion==6')"
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lg-QNLbnXEtl"
      },
      "source": [
        "#Split the data into traing and testing\n",
        "data_train = data.query('Usage==\"Training\" or Usage == \"PublicTest\"')\n",
        "data_test = data.query('Usage==\"PrivateTest\"')"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "d9dHfOfGEatO",
        "outputId": "4dfc78d0-3b19-465b-d523-7c3682c6b7fe"
      },
      "source": [
        "data_train.head()"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>emotion</th>\n",
              "      <th>pixels</th>\n",
              "      <th>Usage</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>151 150 147 155 148 133 111 140 170 174 182 15...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>231 212 156 164 174 138 161 173 182 200 106 38...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6</td>\n",
              "      <td>4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   emotion                                             pixels     Usage\n",
              "0        0  70 80 82 72 58 58 60 63 54 58 60 48 89 115 121...  Training\n",
              "1        0  151 150 147 155 148 133 111 140 170 174 182 15...  Training\n",
              "2        2  231 212 156 164 174 138 161 173 182 200 106 38...  Training\n",
              "3        4  24 32 36 30 32 23 19 20 30 41 21 22 32 34 21 1...  Training\n",
              "4        6  4 0 0 0 0 0 0 0 0 0 0 0 3 15 23 28 48 50 58 84...  Training"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScOAhlMmXEtm"
      },
      "source": [
        "X_train = data_train.iloc[:,1]\n",
        "y_train = data_train.iloc[:,0]\n",
        "\n",
        "X_test = data_test.iloc[:,1]\n",
        "y_test = data_test.iloc[:,0]"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ksTRU_wkXEtn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be1b3723-5a10-4900-ee0f-878b1ef1d19f"
      },
      "source": [
        "print(X_train.shape)"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(28220,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0e4EETKXEtn"
      },
      "source": [
        "#Make the data ready for CNN\n",
        "import numpy as np\n",
        "\n",
        "X_train = X_train.apply(lambda x: np.array(x.split(' ')).reshape(48, 48, 1).astype('float32'))\n",
        "X_train = np.stack(X_train, axis=0)\n",
        "\n",
        "X_test = X_test.apply(lambda x: np.array(x.split(' ')).reshape(48, 48, 1).astype('float32'))\n",
        "X_test = np.stack(X_test, axis=0)"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9JjPizLnXEto"
      },
      "source": [
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "X_test = np.array(X_test)\n",
        "y_test = np.array(y_test)"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xok2s1GGXEtp"
      },
      "source": [
        "from keras.utils import np_utils\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "num_classes = 5\n",
        "le = LabelEncoder()\n",
        "\n",
        "y_train = le.fit_transform(y_train)\n",
        "y_train = np_utils.to_categorical(y_train, num_classes)\n",
        "\n",
        "y_test = le.fit_transform(y_test)\n",
        "y_test = np_utils.to_categorical(y_test, num_classes)\n",
        "\n"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eyBrPeooXEtq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cd1fa1e-8798-4a8f-eee4-7364ede70373"
      },
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(28220, 48, 48, 1)\n",
            "(3118, 48, 48, 1)\n",
            "(28220, 5)\n",
            "(3118, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgz8jJajXEtr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "375f4ec4-3c93-40fe-88dd-05cc8d824c55"
      },
      "source": [
        "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
        "from keras.models import Sequential\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(filters=32, kernel_size=2, activation='relu', input_shape=(48,48,1)))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "\n",
        "model.add(Conv2D(filters=64, kernel_size=2, activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "\n",
        "model.add(Conv2D(filters=128, kernel_size=2, activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "\n",
        "model.add(Conv2D(filters=256, kernel_size=2, activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=2))\n",
        "\n",
        "model.add(Conv2D(filters=512, kernel_size=2, activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=1))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_5 (Conv2D)            (None, 47, 47, 32)        160       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 23, 23, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 22, 22, 64)        8256      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 11, 11, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 10, 10, 128)       32896     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 5, 5, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 5, 5, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 4, 4, 256)         131328    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 2, 2, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 1, 1, 512)         524800    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 1, 1, 512)         0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 1, 1, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_7 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 5)                 2565      \n",
            "=================================================================\n",
            "Total params: 962,661\n",
            "Trainable params: 962,661\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3hx3n8LXEts"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_G1rdFTrXEts"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "early = EarlyStopping(\n",
        "        monitor='val_accuracy', \n",
        "        patience=10,\n",
        "        mode='max',\n",
        "        restore_best_weights=True,\n",
        "        verbose=1)\n",
        "\n",
        "checkpointer = ModelCheckpoint(filepath='FER.hdf5', verbose=1, save_best_only=True)"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ijmYNb_mXEtt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46873182-85e2-4b14-a08b-8fcae167bf27"
      },
      "source": [
        "hist = model.fit(X_train, y_train, batch_size=128, epochs=150, validation_split=0.2, callbacks=[checkpointer, early], verbose=1, shuffle=True)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "177/177 [==============================] - 2s 13ms/step - loss: 0.3671 - accuracy: 0.8717 - val_loss: 1.3819 - val_accuracy: 0.5737\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 1.38190, saving model to FER.hdf5\n",
            "Epoch 2/150\n",
            "177/177 [==============================] - 2s 12ms/step - loss: 0.3692 - accuracy: 0.8664 - val_loss: 1.3713 - val_accuracy: 0.5691\n",
            "\n",
            "Epoch 00002: val_loss improved from 1.38190 to 1.37134, saving model to FER.hdf5\n",
            "Epoch 3/150\n",
            "177/177 [==============================] - 2s 11ms/step - loss: 0.3529 - accuracy: 0.8718 - val_loss: 1.3864 - val_accuracy: 0.5742\n",
            "\n",
            "Epoch 00003: val_loss did not improve from 1.37134\n",
            "Epoch 4/150\n",
            "177/177 [==============================] - 2s 11ms/step - loss: 0.3607 - accuracy: 0.8707 - val_loss: 1.3636 - val_accuracy: 0.5744\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.37134 to 1.36356, saving model to FER.hdf5\n",
            "Epoch 5/150\n",
            "177/177 [==============================] - 2s 12ms/step - loss: 0.3510 - accuracy: 0.8742 - val_loss: 1.4189 - val_accuracy: 0.5817\n",
            "\n",
            "Epoch 00005: val_loss did not improve from 1.36356\n",
            "Epoch 6/150\n",
            "177/177 [==============================] - 2s 12ms/step - loss: 0.3515 - accuracy: 0.8750 - val_loss: 1.3993 - val_accuracy: 0.5650\n",
            "\n",
            "Epoch 00006: val_loss did not improve from 1.36356\n",
            "Epoch 7/150\n",
            "177/177 [==============================] - 2s 12ms/step - loss: 0.3569 - accuracy: 0.8727 - val_loss: 1.4022 - val_accuracy: 0.5776\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 1.36356\n",
            "Epoch 8/150\n",
            "177/177 [==============================] - 2s 11ms/step - loss: 0.3365 - accuracy: 0.8785 - val_loss: 1.4216 - val_accuracy: 0.5728\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 1.36356\n",
            "Epoch 9/150\n",
            "177/177 [==============================] - 2s 11ms/step - loss: 0.3379 - accuracy: 0.8786 - val_loss: 1.4739 - val_accuracy: 0.5718\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 1.36356\n",
            "Epoch 10/150\n",
            "177/177 [==============================] - 2s 12ms/step - loss: 0.3432 - accuracy: 0.8767 - val_loss: 1.4389 - val_accuracy: 0.5680\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 1.36356\n",
            "Epoch 11/150\n",
            "177/177 [==============================] - 2s 12ms/step - loss: 0.3477 - accuracy: 0.8771 - val_loss: 1.4220 - val_accuracy: 0.5753\n",
            "\n",
            "Epoch 00011: val_loss did not improve from 1.36356\n",
            "Epoch 12/150\n",
            "177/177 [==============================] - 2s 12ms/step - loss: 0.3345 - accuracy: 0.8793 - val_loss: 1.4258 - val_accuracy: 0.5703\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 1.36356\n",
            "Epoch 13/150\n",
            "177/177 [==============================] - 2s 12ms/step - loss: 0.3394 - accuracy: 0.8782 - val_loss: 1.4481 - val_accuracy: 0.5709\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 1.36356\n",
            "Epoch 14/150\n",
            "177/177 [==============================] - 2s 11ms/step - loss: 0.3301 - accuracy: 0.8822 - val_loss: 1.4093 - val_accuracy: 0.5712\n",
            "\n",
            "Epoch 00014: val_loss did not improve from 1.36356\n",
            "Epoch 15/150\n",
            "177/177 [==============================] - 2s 12ms/step - loss: 0.3260 - accuracy: 0.8830 - val_loss: 1.4913 - val_accuracy: 0.5744\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 1.36356\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00015: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AELnRsfGvwf"
      },
      "source": [
        "model.load_weights('FER.hdf5')"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESXtR-8lG3LF"
      },
      "source": [
        "score = model.evaluate(X_test, y_test, verbose=0)"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGomTsdsHA6F",
        "outputId": "4a7cb11c-147e-467e-bd44-a794b740ad4a"
      },
      "source": [
        "print(score[1])"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5859525203704834\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7MaUQXyGiMQ"
      },
      "source": [
        "So by training my own CNN I was able to get an accuracy of  58.5%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8nrs5H2XEtt"
      },
      "source": [
        "from keras.applications.vgg16 import VGG16"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLgqRMSbP6l5"
      },
      "source": [
        "#The data is grayscale, and VGG is trained on RGB images.\r\n",
        "#So to get around this issue\r\n",
        "\r\n",
        "from keras import backend as K\r\n",
        "\r\n",
        "def grayscale_to_rgb(images, channel_axis=-1):\r\n",
        "    #images= K.expand_dims(images, axis=channel_axis)\r\n",
        "    tiling = [1] * 4    # 4 dimensions: B, H, W, C\r\n",
        "    tiling[channel_axis] *= 3\r\n",
        "    images= K.tile(images, tiling)\r\n",
        "    return images"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bg_Vu17xbt8i"
      },
      "source": [
        "X_train = grayscale_to_rgb(X_train)\r\n",
        "X_test = grayscale_to_rgb(X_test)"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFtWpaaibvy5",
        "outputId": "ffa59719-2f20-4581-a310-e8ac1f98cfdb"
      },
      "source": [
        "print(X_train.shape)\r\n",
        "print(X_test.shape)"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(28220, 48, 48, 3)\n",
            "(3118, 48, 48, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YToZH6DpQOjj"
      },
      "source": [
        "model_vgg = VGG16(include_top=False, weights='imagenet', input_shape=[48,48,3])"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vysZKCJ5Qrke"
      },
      "source": [
        "#Not to train the entire model\r\n",
        "for layer in model_vgg.layers:\r\n",
        "  layer.trainable=False"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S_TFBO7kRZ3X"
      },
      "source": [
        "#Add last fully connected layers\r\n",
        "\r\n",
        "x = Flatten()(model_vgg.output)\r\n",
        "prediction = Dense(5,activation='softmax')(x)"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbYclYoCSJTZ"
      },
      "source": [
        "from keras.models import Model\r\n",
        "model_vgg1 = Model(inputs=model_vgg.input, outputs=prediction)"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1N8arG4Tzas",
        "outputId": "1a6f4a3a-c65f-43ef-c7d8-c6b59745cd08"
      },
      "source": [
        "model_vgg1.summary()"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         [(None, 48, 48, 3)]       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 48, 48, 64)        1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 48, 48, 64)        36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 24, 24, 64)        0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 24, 24, 128)       73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 24, 24, 128)       147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 12, 12, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 12, 12, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 12, 12, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 12, 12, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 6, 6, 512)         1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 6, 6, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 3, 3, 512)         0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 3, 3, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten_8 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 5)                 2565      \n",
            "=================================================================\n",
            "Total params: 14,717,253\n",
            "Trainable params: 2,565\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxhaMTuMUJU4"
      },
      "source": [
        "model_vgg1.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2VEJ8DMUZLc"
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\r\n",
        "\r\n",
        "early = EarlyStopping(\r\n",
        "        monitor='val_accuracy', \r\n",
        "        patience=10,\r\n",
        "        mode='max',\r\n",
        "        restore_best_weights=True,\r\n",
        "        verbose=1)\r\n",
        "\r\n",
        "checkpointer = ModelCheckpoint(filepath='FER.vgg.hdf5', verbose=1, save_best_only=True)"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CTBn077JedJb",
        "outputId": "8a2ff4b6-74ef-492b-9193-dd9336810659"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28220, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLQSwbqIUede",
        "outputId": "69b70656-75ab-4fee-c4ee-36e3d655ec8b"
      },
      "source": [
        "hist = model_vgg1.fit(X_train, y_train, batch_size=128, epochs=150,\r\n",
        "                 validation_split=0.2, callbacks=[checkpointer, early], verbose=1, shuffle=True)"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "177/177 [==============================] - 8s 40ms/step - loss: 13.7512 - accuracy: 0.2450 - val_loss: 4.6032 - val_accuracy: 0.3154\n",
            "\n",
            "Epoch 00001: val_loss improved from inf to 4.60324, saving model to FER.vgg.hdf5\n",
            "Epoch 2/150\n",
            "177/177 [==============================] - 6s 37ms/step - loss: 3.7204 - accuracy: 0.3245 - val_loss: 2.4079 - val_accuracy: 0.3409\n",
            "\n",
            "Epoch 00002: val_loss improved from 4.60324 to 2.40785, saving model to FER.vgg.hdf5\n",
            "Epoch 3/150\n",
            "177/177 [==============================] - 6s 37ms/step - loss: 2.0229 - accuracy: 0.3731 - val_loss: 1.7739 - val_accuracy: 0.3604\n",
            "\n",
            "Epoch 00003: val_loss improved from 2.40785 to 1.77392, saving model to FER.vgg.hdf5\n",
            "Epoch 4/150\n",
            "177/177 [==============================] - 7s 37ms/step - loss: 1.5943 - accuracy: 0.4038 - val_loss: 1.6704 - val_accuracy: 0.3721\n",
            "\n",
            "Epoch 00004: val_loss improved from 1.77392 to 1.67041, saving model to FER.vgg.hdf5\n",
            "Epoch 5/150\n",
            "177/177 [==============================] - 7s 37ms/step - loss: 1.5253 - accuracy: 0.4067 - val_loss: 1.6507 - val_accuracy: 0.3659\n",
            "\n",
            "Epoch 00005: val_loss improved from 1.67041 to 1.65068, saving model to FER.vgg.hdf5\n",
            "Epoch 6/150\n",
            "177/177 [==============================] - 7s 37ms/step - loss: 1.5104 - accuracy: 0.4051 - val_loss: 1.5910 - val_accuracy: 0.3815\n",
            "\n",
            "Epoch 00006: val_loss improved from 1.65068 to 1.59098, saving model to FER.vgg.hdf5\n",
            "Epoch 7/150\n",
            "177/177 [==============================] - 7s 37ms/step - loss: 1.4897 - accuracy: 0.4105 - val_loss: 1.6273 - val_accuracy: 0.3758\n",
            "\n",
            "Epoch 00007: val_loss did not improve from 1.59098\n",
            "Epoch 8/150\n",
            "177/177 [==============================] - 7s 37ms/step - loss: 1.5052 - accuracy: 0.4039 - val_loss: 1.6384 - val_accuracy: 0.3753\n",
            "\n",
            "Epoch 00008: val_loss did not improve from 1.59098\n",
            "Epoch 9/150\n",
            "177/177 [==============================] - 7s 37ms/step - loss: 1.5235 - accuracy: 0.3986 - val_loss: 1.6235 - val_accuracy: 0.3753\n",
            "\n",
            "Epoch 00009: val_loss did not improve from 1.59098\n",
            "Epoch 10/150\n",
            "177/177 [==============================] - 7s 37ms/step - loss: 1.4996 - accuracy: 0.3994 - val_loss: 1.6318 - val_accuracy: 0.3900\n",
            "\n",
            "Epoch 00010: val_loss did not improve from 1.59098\n",
            "Epoch 11/150\n",
            "177/177 [==============================] - 7s 37ms/step - loss: 1.5070 - accuracy: 0.4050 - val_loss: 1.5660 - val_accuracy: 0.3859\n",
            "\n",
            "Epoch 00011: val_loss improved from 1.59098 to 1.56604, saving model to FER.vgg.hdf5\n",
            "Epoch 12/150\n",
            "177/177 [==============================] - 7s 38ms/step - loss: 1.4906 - accuracy: 0.4104 - val_loss: 1.5942 - val_accuracy: 0.3804\n",
            "\n",
            "Epoch 00012: val_loss did not improve from 1.56604\n",
            "Epoch 13/150\n",
            "177/177 [==============================] - 7s 38ms/step - loss: 1.4969 - accuracy: 0.4051 - val_loss: 1.5752 - val_accuracy: 0.3932\n",
            "\n",
            "Epoch 00013: val_loss did not improve from 1.56604\n",
            "Epoch 14/150\n",
            "177/177 [==============================] - 7s 38ms/step - loss: 1.4906 - accuracy: 0.4078 - val_loss: 1.5651 - val_accuracy: 0.3848\n",
            "\n",
            "Epoch 00014: val_loss improved from 1.56604 to 1.56515, saving model to FER.vgg.hdf5\n",
            "Epoch 15/150\n",
            "177/177 [==============================] - 7s 38ms/step - loss: 1.5158 - accuracy: 0.4051 - val_loss: 1.6364 - val_accuracy: 0.3820\n",
            "\n",
            "Epoch 00015: val_loss did not improve from 1.56515\n",
            "Epoch 16/150\n",
            "177/177 [==============================] - 7s 38ms/step - loss: 1.5025 - accuracy: 0.4045 - val_loss: 1.5734 - val_accuracy: 0.3875\n",
            "\n",
            "Epoch 00016: val_loss did not improve from 1.56515\n",
            "Epoch 17/150\n",
            "177/177 [==============================] - 7s 39ms/step - loss: 1.5002 - accuracy: 0.4066 - val_loss: 1.6185 - val_accuracy: 0.3878\n",
            "\n",
            "Epoch 00017: val_loss did not improve from 1.56515\n",
            "Epoch 18/150\n",
            "177/177 [==============================] - 7s 39ms/step - loss: 1.4956 - accuracy: 0.4091 - val_loss: 1.5896 - val_accuracy: 0.3873\n",
            "\n",
            "Epoch 00018: val_loss did not improve from 1.56515\n",
            "Epoch 19/150\n",
            "177/177 [==============================] - 7s 39ms/step - loss: 1.4903 - accuracy: 0.4057 - val_loss: 1.5680 - val_accuracy: 0.3898\n",
            "\n",
            "Epoch 00019: val_loss did not improve from 1.56515\n",
            "Epoch 20/150\n",
            "177/177 [==============================] - 7s 40ms/step - loss: 1.4703 - accuracy: 0.4133 - val_loss: 1.6240 - val_accuracy: 0.3776\n",
            "\n",
            "Epoch 00020: val_loss did not improve from 1.56515\n",
            "Epoch 21/150\n",
            "177/177 [==============================] - 7s 39ms/step - loss: 1.4961 - accuracy: 0.4107 - val_loss: 1.5982 - val_accuracy: 0.3733\n",
            "\n",
            "Epoch 00021: val_loss did not improve from 1.56515\n",
            "Epoch 22/150\n",
            "177/177 [==============================] - 7s 39ms/step - loss: 1.4876 - accuracy: 0.4064 - val_loss: 1.6271 - val_accuracy: 0.3829\n",
            "\n",
            "Epoch 00022: val_loss did not improve from 1.56515\n",
            "Epoch 23/150\n",
            "177/177 [==============================] - 7s 39ms/step - loss: 1.5069 - accuracy: 0.4030 - val_loss: 1.5691 - val_accuracy: 0.3942\n",
            "\n",
            "Epoch 00023: val_loss did not improve from 1.56515\n",
            "Epoch 24/150\n",
            "177/177 [==============================] - 7s 39ms/step - loss: 1.4955 - accuracy: 0.4099 - val_loss: 1.6321 - val_accuracy: 0.3825\n",
            "\n",
            "Epoch 00024: val_loss did not improve from 1.56515\n",
            "Epoch 25/150\n",
            "177/177 [==============================] - 7s 39ms/step - loss: 1.4991 - accuracy: 0.4135 - val_loss: 1.6208 - val_accuracy: 0.3843\n",
            "\n",
            "Epoch 00025: val_loss did not improve from 1.56515\n",
            "Epoch 26/150\n",
            "177/177 [==============================] - 7s 39ms/step - loss: 1.5038 - accuracy: 0.4052 - val_loss: 1.5755 - val_accuracy: 0.3854\n",
            "\n",
            "Epoch 00026: val_loss did not improve from 1.56515\n",
            "Epoch 27/150\n",
            "177/177 [==============================] - 7s 39ms/step - loss: 1.4981 - accuracy: 0.4067 - val_loss: 1.6181 - val_accuracy: 0.3880\n",
            "\n",
            "Epoch 00027: val_loss did not improve from 1.56515\n",
            "Epoch 28/150\n",
            "177/177 [==============================] - 7s 39ms/step - loss: 1.4869 - accuracy: 0.4084 - val_loss: 1.6015 - val_accuracy: 0.3921\n",
            "\n",
            "Epoch 00028: val_loss did not improve from 1.56515\n",
            "Epoch 29/150\n",
            "177/177 [==============================] - 7s 39ms/step - loss: 1.4960 - accuracy: 0.4078 - val_loss: 1.6309 - val_accuracy: 0.3811\n",
            "\n",
            "Epoch 00029: val_loss did not improve from 1.56515\n",
            "Epoch 30/150\n",
            "177/177 [==============================] - 7s 39ms/step - loss: 1.5001 - accuracy: 0.4100 - val_loss: 1.6279 - val_accuracy: 0.3806\n",
            "\n",
            "Epoch 00030: val_loss did not improve from 1.56515\n",
            "Epoch 31/150\n",
            "177/177 [==============================] - 7s 39ms/step - loss: 1.4921 - accuracy: 0.4103 - val_loss: 1.6144 - val_accuracy: 0.3942\n",
            "\n",
            "Epoch 00031: val_loss did not improve from 1.56515\n",
            "Epoch 32/150\n",
            "177/177 [==============================] - 7s 39ms/step - loss: 1.5057 - accuracy: 0.4054 - val_loss: 1.6233 - val_accuracy: 0.3728\n",
            "\n",
            "Epoch 00032: val_loss did not improve from 1.56515\n",
            "Epoch 33/150\n",
            "177/177 [==============================] - 7s 39ms/step - loss: 1.5085 - accuracy: 0.4100 - val_loss: 1.6646 - val_accuracy: 0.3733\n",
            "\n",
            "Epoch 00033: val_loss did not improve from 1.56515\n",
            "Restoring model weights from the end of the best epoch.\n",
            "Epoch 00033: early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41yAt_xTUjqK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}